{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f872d42a",
   "metadata": {},
   "source": [
    "## Importando Bibliotecas e Carregando Bases de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15c85673",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import unicodedata\n",
    "from collections import defaultdict\n",
    "\n",
    "from itertools import combinations\n",
    "from ortools.sat.python import cp_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d2e3d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ID",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Nome_Pessoa",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Nome_Empresa",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Ramo",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Pref1_Ramo",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Pref2_Ramo",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Pref3_Ramo",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Fixo",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "Mesa_Fixa",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Assento_Fixo",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "b3b13db5-5347-4d15-9761-43add52e060f",
       "rows": [
        [
         "0",
         "0",
         "Adriana de Souza Torres",
         "Dri Torres Terapeuta",
         "Terapia",
         null,
         null,
         null,
         "False",
         null,
         null
        ],
        [
         "1",
         "1",
         "Ailton Nunes",
         "Bela Festa Locações",
         "Eventos",
         null,
         null,
         null,
         "False",
         null,
         null
        ],
        [
         "2",
         "2",
         "Alessandra Ribeiro",
         "Remax B12",
         "Construção e Imobiliário",
         null,
         null,
         null,
         "False",
         null,
         null
        ],
        [
         "3",
         "3",
         "Alessandra Sallum Bueno",
         "EXPERIÊNCIA 40+",
         "Eventos",
         null,
         null,
         null,
         "False",
         null,
         null
        ],
        [
         "4",
         "4",
         "Ana Claudia Soares",
         "Terapeuta",
         "Terapia",
         null,
         null,
         null,
         "False",
         null,
         null
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Nome_Pessoa</th>\n",
       "      <th>Nome_Empresa</th>\n",
       "      <th>Ramo</th>\n",
       "      <th>Pref1_Ramo</th>\n",
       "      <th>Pref2_Ramo</th>\n",
       "      <th>Pref3_Ramo</th>\n",
       "      <th>Fixo</th>\n",
       "      <th>Mesa_Fixa</th>\n",
       "      <th>Assento_Fixo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Adriana de Souza Torres</td>\n",
       "      <td>Dri Torres Terapeuta</td>\n",
       "      <td>Terapia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Ailton Nunes</td>\n",
       "      <td>Bela Festa Locações</td>\n",
       "      <td>Eventos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Alessandra Ribeiro</td>\n",
       "      <td>Remax B12</td>\n",
       "      <td>Construção e Imobiliário</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Alessandra Sallum Bueno</td>\n",
       "      <td>EXPERIÊNCIA 40+</td>\n",
       "      <td>Eventos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Ana Claudia Soares</td>\n",
       "      <td>Terapeuta</td>\n",
       "      <td>Terapia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID              Nome_Pessoa          Nome_Empresa  \\\n",
       "0   0  Adriana de Souza Torres  Dri Torres Terapeuta   \n",
       "1   1             Ailton Nunes   Bela Festa Locações   \n",
       "2   2       Alessandra Ribeiro             Remax B12   \n",
       "3   3  Alessandra Sallum Bueno       EXPERIÊNCIA 40+   \n",
       "4   4       Ana Claudia Soares             Terapeuta   \n",
       "\n",
       "                       Ramo Pref1_Ramo Pref2_Ramo Pref3_Ramo   Fixo  \\\n",
       "0                   Terapia        NaN        NaN        NaN  False   \n",
       "1                   Eventos        NaN        NaN        NaN  False   \n",
       "2  Construção e Imobiliário        NaN        NaN        NaN  False   \n",
       "3                   Eventos        NaN        NaN        NaN  False   \n",
       "4                   Terapia        NaN        NaN        NaN  False   \n",
       "\n",
       "   Mesa_Fixa  Assento_Fixo  \n",
       "0        NaN           NaN  \n",
       "1        NaN           NaN  \n",
       "2        NaN           NaN  \n",
       "3        NaN           NaN  \n",
       "4        NaN           NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ID_A",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Nome_A",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ID_B",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Nome_B",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "142a8012-3b34-4d58-b7fd-97a87ae23c80",
       "rows": [
        [
         "0",
         "55",
         "Silene Darin",
         "57",
         "Silviä Castro"
        ],
        [
         "1",
         "62",
         "Walter Junior",
         "11",
         "Caroline Scorvo"
        ],
        [
         "2",
         "41",
         "Mariana Gobbo",
         "26",
         "Fabiano Souza Ramos"
        ],
        [
         "3",
         "41",
         "Mariana Gobbo",
         "51",
         "Rosana Matos"
        ],
        [
         "4",
         "41",
         "Mariana Gobbo",
         "4",
         "Ana Claudia Soares"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_A</th>\n",
       "      <th>Nome_A</th>\n",
       "      <th>ID_B</th>\n",
       "      <th>Nome_B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55</td>\n",
       "      <td>Silene Darin</td>\n",
       "      <td>57</td>\n",
       "      <td>Silviä Castro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>Walter Junior</td>\n",
       "      <td>11</td>\n",
       "      <td>Caroline Scorvo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>Mariana Gobbo</td>\n",
       "      <td>26</td>\n",
       "      <td>Fabiano Souza Ramos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41</td>\n",
       "      <td>Mariana Gobbo</td>\n",
       "      <td>51</td>\n",
       "      <td>Rosana Matos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>Mariana Gobbo</td>\n",
       "      <td>4</td>\n",
       "      <td>Ana Claudia Soares</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_A         Nome_A  ID_B               Nome_B\n",
       "0    55   Silene Darin    57        Silviä Castro\n",
       "1    62  Walter Junior    11      Caroline Scorvo\n",
       "2    41  Mariana Gobbo    26  Fabiano Souza Ramos\n",
       "3    41  Mariana Gobbo    51         Rosana Matos\n",
       "4    41  Mariana Gobbo     4   Ana Claudia Soares"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ID_A",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Nome_A",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ID_B",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Nome_B",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "b737aea6-74b5-4750-b4e7-ac4ee422140b",
       "rows": [
        [
         "0",
         "14",
         "Cidinha Lins",
         "7",
         "Bervelyn Alecrim"
        ],
        [
         "1",
         "14",
         "Cidinha Lins",
         "54",
         "Silene  Silva"
        ],
        [
         "2",
         "18",
         "Deise Gressens",
         "58",
         "Tiago  Vasconcelos"
        ],
        [
         "3",
         "22",
         "Evelyn Silva",
         "60",
         "Tiago Santos"
        ],
        [
         "4",
         "40",
         "Maria Vasconcelos",
         "58",
         "Tiago  Vasconcelos"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_A</th>\n",
       "      <th>Nome_A</th>\n",
       "      <th>ID_B</th>\n",
       "      <th>Nome_B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>Cidinha Lins</td>\n",
       "      <td>7</td>\n",
       "      <td>Bervelyn Alecrim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>Cidinha Lins</td>\n",
       "      <td>54</td>\n",
       "      <td>Silene  Silva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>Deise Gressens</td>\n",
       "      <td>58</td>\n",
       "      <td>Tiago  Vasconcelos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>Evelyn Silva</td>\n",
       "      <td>60</td>\n",
       "      <td>Tiago Santos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>Maria Vasconcelos</td>\n",
       "      <td>58</td>\n",
       "      <td>Tiago  Vasconcelos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_A             Nome_A  ID_B              Nome_B\n",
       "0    14       Cidinha Lins     7    Bervelyn Alecrim\n",
       "1    14       Cidinha Lins    54       Silene  Silva\n",
       "2    18     Deise Gressens    58  Tiago  Vasconcelos\n",
       "3    22       Evelyn Silva    60        Tiago Santos\n",
       "4    40  Maria Vasconcelos    58  Tiago  Vasconcelos"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "entrada",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "normalizado",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "macro_ramo",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "8f21e892-b990-45f7-b892-2f8ec991f108",
       "rows": [
        [
         "0",
         "Adestrador",
         "pet",
         "pet"
        ],
        [
         "1",
         "Automação",
         "tecnologia",
         "tecnologia"
        ],
        [
         "2",
         "Coaching",
         "consultoria",
         "consultoria"
        ],
        [
         "3",
         "Construção e Imobiliário",
         "construcao_imobiliario",
         "construcao_imobiliario"
        ],
        [
         "4",
         "Consultoria Comercial",
         "consultoria",
         "consultoria"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entrada</th>\n",
       "      <th>normalizado</th>\n",
       "      <th>macro_ramo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adestrador</td>\n",
       "      <td>pet</td>\n",
       "      <td>pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Automação</td>\n",
       "      <td>tecnologia</td>\n",
       "      <td>tecnologia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coaching</td>\n",
       "      <td>consultoria</td>\n",
       "      <td>consultoria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Construção e Imobiliário</td>\n",
       "      <td>construcao_imobiliario</td>\n",
       "      <td>construcao_imobiliario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Consultoria Comercial</td>\n",
       "      <td>consultoria</td>\n",
       "      <td>consultoria</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    entrada             normalizado              macro_ramo\n",
       "0                Adestrador                     pet                     pet\n",
       "1                 Automação              tecnologia              tecnologia\n",
       "2                  Coaching             consultoria             consultoria\n",
       "3  Construção e Imobiliário  construcao_imobiliario  construcao_imobiliario\n",
       "4     Consultoria Comercial             consultoria             consultoria"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ramo_a",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ramo_b",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sim",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "a357297a-7c21-48fd-9f22-c3c5cc9621a9",
       "rows": [
        [
         "0",
         "marketing",
         "eventos",
         "0.9"
        ],
        [
         "1",
         "marketing",
         "varejo_especializado",
         "0.85"
        ],
        [
         "2",
         "marketing",
         "automotivo",
         "0.8"
        ],
        [
         "3",
         "marketing",
         "tecnologia",
         "0.8"
        ],
        [
         "4",
         "marketing",
         "saude",
         "0.75"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ramo_a</th>\n",
       "      <th>ramo_b</th>\n",
       "      <th>sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>marketing</td>\n",
       "      <td>eventos</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>marketing</td>\n",
       "      <td>varejo_especializado</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>marketing</td>\n",
       "      <td>automotivo</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>marketing</td>\n",
       "      <td>tecnologia</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>marketing</td>\n",
       "      <td>saude</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ramo_a                ramo_b   sim\n",
       "0  marketing               eventos  0.90\n",
       "1  marketing  varejo_especializado  0.85\n",
       "2  marketing            automotivo  0.80\n",
       "3  marketing            tecnologia  0.80\n",
       "4  marketing                 saude  0.75"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "participants = pd.read_excel('Rodada_Negocios_Netweaving_27102025_3.xlsx', sheet_name='Participants')\n",
    "must_together = pd.read_excel('Rodada_Negocios_Netweaving_27102025_3.xlsx', sheet_name='Must_Together_2')\n",
    "must_avoid = pd.read_excel('Rodada_Negocios_Netweaving_27102025_3.xlsx', sheet_name='Must_Avoid')\n",
    "ramo_alias = pd.read_csv('ramo_alias.csv')\n",
    "affinity_overrides = pd.read_csv('affinity_overrides.csv')\n",
    "\n",
    "display(participants.head())\n",
    "display(must_together.head())\n",
    "display(must_avoid.head())\n",
    "display(ramo_alias.head())\n",
    "display(affinity_overrides.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf96734",
   "metadata": {},
   "source": [
    "## Script Otimização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746cac06",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Modelo infeasible (verifique pares must_avoid/must_together e distribuição de fixos).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 355\u001b[39m\n\u001b[32m    353\u001b[39m status = solver.Solve(model)\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (cp_model.OPTIMAL, cp_model.FEASIBLE):\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mModelo infeasible (verifique pares must_avoid/must_together e distribuição de fixos).\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    357\u001b[39m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[32m    358\u001b[39m \u001b[38;5;66;03m# Extrai solução\u001b[39;00m\n\u001b[32m    359\u001b[39m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[32m    360\u001b[39m assign = {(r,t): [] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m R \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m T}\n",
      "\u001b[31mRuntimeError\u001b[39m: Modelo infeasible (verifique pares must_avoid/must_together e distribuição de fixos)."
     ]
    }
   ],
   "source": [
    "# === Otimizador de Rodada de Negócios (CP-SAT / OR-Tools) — versão com fixos robustos ===\n",
    "# Entradas já carregadas: participants, must_together, must_avoid, ramo_alias, affinity_overrides\n",
    "\n",
    "# -------------------------\n",
    "# Parâmetros do evento\n",
    "# -------------------------\n",
    "ROUNDS = 4\n",
    "TABLES = 17\n",
    "SEATS_PER_TABLE = 4\n",
    "\n",
    "# -------------------------\n",
    "# Pesos (ajuste fino)\n",
    "# -------------------------\n",
    "W_TOGETHER = 5000\n",
    "W_SIM = 10\n",
    "W_PREF1 = 300\n",
    "W_PREF2 = 180\n",
    "W_PREF3 = 90\n",
    "PREF_FILLED_BOOST = 1.5\n",
    "W_OVER = 800\n",
    "DEFAULT_SIM_SAME = 0.30\n",
    "DEFAULT_SIM_DIFF = 0.55\n",
    "\n",
    "MAX_TIME_S = 30\n",
    "N_WORKERS = 8\n",
    "\n",
    "# -------------------------\n",
    "# Normalização por alias\n",
    "# -------------------------\n",
    "def strip_accents(s: str) -> str:\n",
    "    if pd.isna(s):\n",
    "        return \"\"\n",
    "    s = str(s).strip().lower()\n",
    "    s = unicodedata.normalize(\"NFKD\", s)\n",
    "    s = \"\".join(c for c in s if not unicodedata.combining(c))\n",
    "    return s\n",
    "\n",
    "alias_map = {}\n",
    "if {'entrada','normalizado'}.issubset({c.lower() for c in ramo_alias.columns}):\n",
    "    _entrada = [c for c in ramo_alias.columns if c.lower()=='entrada'][0]\n",
    "    _normalizado = [c for c in ramo_alias.columns if c.lower()=='normalizado'][0]\n",
    "    for _,row in ramo_alias.iterrows():\n",
    "        k = strip_accents(row[_entrada])\n",
    "        v = str(row[_normalizado]).strip().lower()\n",
    "        if k:\n",
    "            alias_map[k] = v\n",
    "\n",
    "def alias_norm(x: str) -> str:\n",
    "    k = strip_accents(x)\n",
    "    return alias_map.get(k, k if k else \"outros\")\n",
    "\n",
    "# -------------------------\n",
    "# Preparo dos participants\n",
    "# -------------------------\n",
    "cols = {c.lower(): c for c in participants.columns}\n",
    "getcol = lambda name: cols.get(name)\n",
    "\n",
    "id_col       = getcol('id')\n",
    "nome_col     = getcol('nome_pessoa') or getcol('nome') or getcol('pessoa') or getcol('nome completo')\n",
    "empresa_col  = getcol('nome_empresa') or getcol('empresa')\n",
    "ramo_col     = getcol('ramo')\n",
    "pref1_col    = getcol('pref1_ramo')\n",
    "pref2_col    = getcol('pref2_ramo')\n",
    "pref3_col    = getcol('pref3_ramo')\n",
    "fixo_col     = getcol('fixo')          # pode não existir\n",
    "mesa_fixa_col= getcol('mesa_fixa') or getcol('mesa fixa') or getcol('mesa fixa ')\n",
    "\n",
    "dfP = participants.copy()\n",
    "\n",
    "# id\n",
    "if id_col is None:\n",
    "    dfP['id'] = np.arange(len(dfP))\n",
    "    id_col = 'id'\n",
    "\n",
    "# nome/empresa/ramo (obrigatórios)\n",
    "if nome_col is None:\n",
    "    raise ValueError(\"Coluna 'nome_pessoa' (ou equivalente) não encontrada em Participants.\")\n",
    "if empresa_col is None:\n",
    "    raise ValueError(\"Coluna 'nome_empresa' (ou equivalente) não encontrada em Participants.\")\n",
    "if ramo_col is None:\n",
    "    raise ValueError(\"Coluna 'ramo' não encontrada em Participants.\")\n",
    "\n",
    "# normaliza ramo e prefs\n",
    "dfP['ramo_norm'] = dfP[ramo_col].astype(str).apply(alias_norm)\n",
    "for colname, newname in [(pref1_col,'pref1_norm'), (pref2_col,'pref2_norm'), (pref3_col,'pref3_norm')]:\n",
    "    if colname:\n",
    "        dfP[newname] = dfP[colname].astype(str).apply(lambda x: alias_norm(x) if str(x).strip() != \"\" else \"\")\n",
    "    else:\n",
    "        dfP[newname] = \"\"\n",
    "\n",
    "# mesa fixa: força fixo=1 quando houver mesa definida\n",
    "if mesa_fixa_col is None:\n",
    "    dfP['mesa_fixa'] = np.nan\n",
    "    mesa_fixa_col = 'mesa_fixa'\n",
    "else:\n",
    "    dfP['mesa_fixa'] = pd.to_numeric(dfP[mesa_fixa_col], errors='coerce')\n",
    "\n",
    "# Heurística de base 1 → base 0 (se todos valores válidos estiverem em 1..TABLES e não houver 0)\n",
    "if dfP['mesa_fixa'].notna().any():\n",
    "    mf_nonnull = dfP['mesa_fixa'].dropna()\n",
    "    cond_one_based = (mf_nonnull.min() >= 1) and (mf_nonnull.max() <= TABLES) and (0 not in set(mf_nonnull.astype(int)))\n",
    "    if cond_one_based:\n",
    "        dfP.loc[dfP['mesa_fixa'].notna(), 'mesa_fixa'] = dfP.loc[dfP['mesa_fixa'].notna(), 'mesa_fixa'].astype(int) - 1\n",
    "\n",
    "# fixo (coluna pode não existir; aceita números, bools, strings)\n",
    "def _to_bool01(x):\n",
    "    if pd.isna(x): return 0\n",
    "    if isinstance(x, (int, np.integer)): return 1 if int(x)!=0 else 0\n",
    "    if isinstance(x, float): \n",
    "        if np.isnan(x): return 0\n",
    "        return 1 if int(round(x))!=0 else 0\n",
    "    s = str(x).strip().lower()\n",
    "    return 1 if s in {'1','true','t','sim','yes','y'} else 0\n",
    "\n",
    "if fixo_col is None:\n",
    "    dfP['fixo'] = 0\n",
    "else:\n",
    "    dfP['fixo'] = dfP[fixo_col].apply(_to_bool01)\n",
    "\n",
    "# **Regra nova**: quem tem mesa_fixa preenchida vira fixo=1 (sobrepõe)\n",
    "dfP.loc[dfP['mesa_fixa'].notna(), 'fixo'] = 1\n",
    "\n",
    "# sanity básico\n",
    "N = len(dfP)\n",
    "if N != TABLES * SEATS_PER_TABLE:\n",
    "    print(f\"[Aviso] Há {N} participantes, mas a configuração espera {TABLES*SEATS_PER_TABLE}. \"\n",
    "          f\"Ainda assim o solver tentará alocar exatamente 4 por mesa por rodada.\")\n",
    "\n",
    "# mapeamentos\n",
    "P_ids = list(dfP[id_col].tolist())\n",
    "id_to_idx = {pid:i for i,pid in enumerate(P_ids)}\n",
    "\n",
    "names    = dfP[nome_col].astype(str).tolist()\n",
    "empresas = dfP[empresa_col].astype(str).tolist()\n",
    "ind_of   = dfP['ramo_norm'].astype(str).tolist()\n",
    "pref1    = dfP['pref1_norm'].astype(str).tolist()\n",
    "pref2    = dfP['pref2_norm'].astype(str).tolist()\n",
    "pref3    = dfP['pref3_norm'].astype(str).tolist()\n",
    "has_pref = [(str(pref1[i]).strip()!=\"\") or (str(pref2[i]).strip()!=\"\") or (str(pref3[i]).strip()!=\"\") for i in range(N)]\n",
    "\n",
    "fixed_info = {}\n",
    "for i in range(N):\n",
    "    if dfP['fixo'].iloc[i] == 1 and pd.notna(dfP['mesa_fixa'].iloc[i]):\n",
    "        mf = int(dfP['mesa_fixa'].iloc[i])\n",
    "        if not (0 <= mf < TABLES):\n",
    "            raise ValueError(f\"Mesa fixa fora do range [0..{TABLES-1}] para {names[i]}: {mf}\")\n",
    "        fixed_info[i] = mf  # fixo por mesa\n",
    "\n",
    "# -------------------------\n",
    "# must_together / must_avoid -> índices\n",
    "# -------------------------\n",
    "def get_pair_df(df, ca='id_a', cb='id_b'):\n",
    "    if df is None or df.empty:\n",
    "        return []\n",
    "    cols = {c.lower(): c for c in df.columns}\n",
    "    A = cols.get(ca.lower(), list(df.columns)[0])\n",
    "    B = cols.get(cb.lower(), list(df.columns)[1])\n",
    "    out = []\n",
    "    for _,row in df.iterrows():\n",
    "        a = row[A]; b = row[B]\n",
    "        if pd.isna(a) or pd.isna(b): continue\n",
    "        a = id_to_idx.get(a, None); b = id_to_idx.get(b, None)\n",
    "        if a is None or b is None or a == b: continue\n",
    "        if a > b: a,b = b,a\n",
    "        out.append((a,b))\n",
    "    return sorted(set(out))\n",
    "\n",
    "must_together_pairs = get_pair_df(must_together)\n",
    "must_avoid_pairs    = get_pair_df(must_avoid)\n",
    "\n",
    "# -------------------------\n",
    "# Pré-checagens (fail-fast)\n",
    "# -------------------------\n",
    "# a) capacidade por mesa só com fixos\n",
    "from collections import Counter\n",
    "fix_count = Counter(fixed_info.values())\n",
    "overcap = {t:c for t,c in fix_count.items() if c > SEATS_PER_TABLE}\n",
    "if overcap:\n",
    "    raise RuntimeError(f\"Capacidade excedida com fixos: {overcap}\")\n",
    "\n",
    "# b) must_avoid com dois fixos mesma mesa\n",
    "bad_avoid = []\n",
    "for (a,b) in must_avoid_pairs:\n",
    "    if (a in fixed_info) and (b in fixed_info) and (fixed_info[a]==fixed_info[b]):\n",
    "        bad_avoid.append((P_ids[a], P_ids[b], fixed_info[a]))\n",
    "if bad_avoid:\n",
    "    raise RuntimeError(f\"Par(es) must_avoid estão fixos na mesma mesa (inviável): {bad_avoid}\")\n",
    "\n",
    "# c) must_together com dois fixos em mesas diferentes\n",
    "bad_mt = []\n",
    "for (a,b) in must_together_pairs:\n",
    "    if (a in fixed_info) and (b in fixed_info) and (fixed_info[a]!=fixed_info[b]):\n",
    "        bad_mt.append((P_ids[a], P_ids[b], fixed_info[a], fixed_info[b]))\n",
    "if bad_mt:\n",
    "    raise RuntimeError(f\"Par(es) must_together fixos em mesas distintas (inviável): {bad_mt}\")\n",
    "\n",
    "# -------------------------\n",
    "# Afinidade (sim) por ramo\n",
    "# -------------------------\n",
    "def sim_lookup(ind_a, ind_b):\n",
    "    ia = str(ind_a).strip().lower()\n",
    "    ib = str(ind_b).strip().lower()\n",
    "    if len(affinity_overrides) > 0:\n",
    "        cols = {c.lower(): c for c in affinity_overrides.columns}\n",
    "        ra = cols.get('ramo_a', list(affinity_overrides.columns)[0])\n",
    "        rb = cols.get('ramo_b', list(affinity_overrides.columns)[1])\n",
    "        rs = cols.get('sim',    list(affinity_overrides.columns)[2])\n",
    "        mask = ((affinity_overrides[ra].str.strip().str.lower()==ia) & \n",
    "                (affinity_overrides[rb].str.strip().str.lower()==ib))\n",
    "        val = affinity_overrides.loc[mask, rs]\n",
    "        if len(val)==0:\n",
    "            mask = ((affinity_overrides[ra].str.strip().str.lower()==ib) & \n",
    "                    (affinity_overrides[rb].str.strip().str.lower()==ia))\n",
    "            val = affinity_overrides.loc[mask, rs]\n",
    "        if len(val)>0:\n",
    "            try:\n",
    "                return float(val.iloc[0])\n",
    "            except:\n",
    "                pass\n",
    "    return DEFAULT_SIM_SAME if ia == ib else DEFAULT_SIM_DIFF\n",
    "\n",
    "sim100 = {}\n",
    "inds_unique = sorted(set(ind_of))\n",
    "for a in inds_unique:\n",
    "    for b in inds_unique:\n",
    "        sim100[(a,b)] = int(round(sim_lookup(a,b) * 100))\n",
    "\n",
    "# -------------------------\n",
    "# Score de preferência (direcional)\n",
    "# -------------------------\n",
    "def pref_dir_score(i_from, i_to):\n",
    "    ramo_to = ind_of[i_to]\n",
    "    s = 0.0\n",
    "    if ramo_to and ramo_to == pref1[i_from]: s += W_PREF1\n",
    "    if ramo_to and ramo_to == pref2[i_from]: s += W_PREF2\n",
    "    if ramo_to and ramo_to == pref3[i_from]: s += W_PREF3\n",
    "    if has_pref[i_from]:\n",
    "        s *= PREF_FILLED_BOOST\n",
    "    return int(round(s))\n",
    "\n",
    "# -------------------------\n",
    "# Modelo CP-SAT\n",
    "# -------------------------\n",
    "R = range(ROUNDS)\n",
    "T = range(TABLES)\n",
    "P = range(N)\n",
    "model = cp_model.CpModel()\n",
    "\n",
    "# X[i,r,t] = 1 se pessoa i está na mesa t na rodada r\n",
    "X = {(i,r,t): model.NewBoolVar(f\"X_{i}_{r}_{t}\") for i in P for r in R for t in T}\n",
    "\n",
    "# 1) Cada pessoa ocupa exatamente 1 mesa por rodada\n",
    "for i in P:\n",
    "    for r in R:\n",
    "        model.Add(sum(X[i,r,t] for t in T) == 1)\n",
    "\n",
    "# 2) Capacidade: 4 por mesa/rodada\n",
    "for r in R:\n",
    "    for t in T:\n",
    "        model.Add(sum(X[i,r,t] for i in P) == SEATS_PER_TABLE)\n",
    "\n",
    "# 3) Fixos: mesa fixa em todas as rodadas\n",
    "for i, mf in fixed_info.items():\n",
    "    for r in R:\n",
    "        model.Add(X[i,r,mf] == 1)\n",
    "\n",
    "# 3b) Não fixos não podem repetir mesa (cada mesa no máx. 1x para a pessoa)\n",
    "for i in P:\n",
    "    if i not in fixed_info:\n",
    "        for t in T:\n",
    "            model.Add(sum(X[i,r,t] for r in R) <= 1)\n",
    "\n",
    "# 4) must_avoid\n",
    "for (a,b) in must_avoid_pairs:\n",
    "    for r in R:\n",
    "        for t in T:\n",
    "            model.Add(X[a,r,t] + X[b,r,t] <= 1)\n",
    "\n",
    "# 5) Indicadores de encontro por par/rodada/mesa (somente a<b)\n",
    "pairs = [(a,b) for (a,b) in combinations(P,2)]\n",
    "B = {}\n",
    "for (a,b) in pairs:\n",
    "    for r in R:\n",
    "        for t in T:\n",
    "            B[a,b,r,t] = model.NewBoolVar(f\"B_{a}_{b}_{r}_{t}\")\n",
    "            model.AddBoolAnd([X[a,r,t], X[b,r,t]]).OnlyEnforceIf(B[a,b,r,t])\n",
    "            model.AddBoolOr([X[a,r,t].Not(), X[b,r,t].Not()]).OnlyEnforceIf(B[a,b,r,t].Not())\n",
    "\n",
    "# 6) Pares não must_together: no máximo 1 encontro no evento\n",
    "must_together_set = set(must_together_pairs)\n",
    "for (a,b) in pairs:\n",
    "    if (a,b) not in must_together_set:\n",
    "        model.Add(sum(B[a,b,r,t] for r in R for t in T) <= 1)\n",
    "\n",
    "# 7) Y[a,b] para must_together atendido\n",
    "Y = {}\n",
    "for (a,b) in must_together_pairs:\n",
    "    Y[a,b] = model.NewBoolVar(f\"Y_{a}_{b}\")\n",
    "    model.Add(Y[a,b] <= sum(B[a,b,r,t] for r in R for t in T))\n",
    "    for r in R:\n",
    "        for t in T:\n",
    "            model.Add(Y[a,b] >= B[a,b,r,t])\n",
    "\n",
    "# 8) Diversidade por mesa: penaliza cnt(ramo) > 1\n",
    "inds_present = sorted(set(ind_of))\n",
    "over_vars = []\n",
    "for r in R:\n",
    "    for t in T:\n",
    "        for ind in inds_present:\n",
    "            cnt = model.NewIntVar(0, SEATS_PER_TABLE, f\"cnt_{ind}_r{r}_t{t}\")\n",
    "            inds_idx = [i for i in P if ind_of[i] == ind]\n",
    "            if len(inds_idx) == 0:\n",
    "                model.Add(cnt == 0)\n",
    "            else:\n",
    "                model.Add(cnt == sum(X[i,r,t] for i in inds_idx))\n",
    "            over = model.NewIntVar(0, SEATS_PER_TABLE, f\"over_{ind}_r{r}_t{t}\")\n",
    "            model.Add(over >= cnt - 1)\n",
    "            model.Add(over >= 0)\n",
    "            over_vars.append(over)\n",
    "\n",
    "# -------------------------\n",
    "# Função objetivo (minimização)\n",
    "# -------------------------\n",
    "obj_terms = []\n",
    "\n",
    "# must_together (max)\n",
    "for (a,b), yvar in Y.items():\n",
    "    obj_terms.append((-W_TOGETHER, yvar))\n",
    "\n",
    "# afinidade + preferências (max)\n",
    "for (a,b) in pairs:\n",
    "    s_sim  = W_SIM * sim100[(ind_of[a], ind_of[b])]\n",
    "    s_pref = pref_dir_score(a, b) + pref_dir_score(b, a)\n",
    "    s_pair = s_sim + s_pref\n",
    "    if s_pair != 0:\n",
    "        for r in R:\n",
    "            for t in T:\n",
    "                obj_terms.append((-s_pair, B[a,b,r,t]))\n",
    "\n",
    "# diversidade (min)\n",
    "for over in over_vars:\n",
    "    obj_terms.append((W_OVER, over))\n",
    "\n",
    "model.Minimize(sum(coef * var for (coef, var) in obj_terms))\n",
    "\n",
    "# -------------------------\n",
    "# Solver\n",
    "# -------------------------\n",
    "solver = cp_model.CpSolver()\n",
    "solver.parameters.max_time_in_seconds = MAX_TIME_S\n",
    "solver.parameters.num_search_workers = N_WORKERS\n",
    "\n",
    "status = solver.Solve(model)\n",
    "if status not in (cp_model.OPTIMAL, cp_model.FEASIBLE):\n",
    "    raise RuntimeError(\"Modelo infeasible (verifique pares must_avoid/must_together e distribuição de fixos).\")\n",
    "\n",
    "# -------------------------\n",
    "# Extrai solução\n",
    "# -------------------------\n",
    "assign = {(r,t): [] for r in R for t in T}\n",
    "for i in range(N):\n",
    "    for r in R:\n",
    "        for t in T:\n",
    "            if solver.Value(X[i,r,t]) == 1:\n",
    "                assign[(r,t)].append(i)\n",
    "\n",
    "# DataFrame longo\n",
    "rows = []\n",
    "for r in R:\n",
    "    for t in T:\n",
    "        for i in assign[(r,t)]:\n",
    "            rows.append({\n",
    "                \"rodada\": r,\n",
    "                \"mesa\": t,\n",
    "                \"id\": P_ids[i],\n",
    "                \"nome_pessoa\": names[i],\n",
    "                \"nome_empresa\": empresas[i],\n",
    "                \"ramo_norm\": ind_of[i],\n",
    "                \"pref1_norm\": pref1[i],\n",
    "                \"pref2_norm\": pref2[i],\n",
    "                \"pref3_norm\": pref3[i],\n",
    "                \"fixo\": int(dfP['fixo'].iloc[i]),\n",
    "                \"mesa_fixa\": int(dfP['mesa_fixa'].iloc[i]) if pd.notna(dfP['mesa_fixa'].iloc[i]) else np.nan,\n",
    "            })\n",
    "schedule_df = pd.DataFrame(rows).sort_values([\"rodada\",\"mesa\",\"nome_pessoa\"]).reset_index(drop=True)\n",
    "\n",
    "# Visual compacto\n",
    "def to_wide(g):\n",
    "    ps = list(g.sort_values(\"nome_pessoa\")[\"nome_pessoa\"])\n",
    "    row = {\"rodada\": int(g[\"rodada\"].iloc[0]), \"mesa\": int(g[\"mesa\"].iloc[0])}\n",
    "    for k, nm in enumerate(ps[:SEATS_PER_TABLE], start=1):\n",
    "        row[f\"p{k}\"] = nm\n",
    "    return pd.Series(row)\n",
    "\n",
    "schedule_wide = (\n",
    "    schedule_df.groupby([\"rodada\",\"mesa\"], as_index=False)\n",
    "    .apply(to_wide)\n",
    "    .sort_values([\"rodada\",\"mesa\"])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Relatórios rápidos\n",
    "mt_att = []\n",
    "for (a,b) in must_together_pairs:\n",
    "    atendeu = 0; r_hit = None; t_hit = None\n",
    "    for r in R:\n",
    "        for t in T:\n",
    "            if solver.Value(B[a,b,r,t]) == 1:\n",
    "                atendeu = 1; r_hit = r; t_hit = t; break\n",
    "        if atendeu: break\n",
    "    mt_att.append({\"id_a\": P_ids[a], \"nome_a\": names[a], \"id_b\": P_ids[b], \"nome_b\": names[b],\n",
    "                   \"atendido\": atendeu, \"rodada\": r_hit, \"mesa\": t_hit})\n",
    "must_together_report = pd.DataFrame(mt_att)\n",
    "\n",
    "ma_viol = []\n",
    "for (a,b) in must_avoid_pairs:\n",
    "    for r in R:\n",
    "        for t in T:\n",
    "            if solver.Value(B[a,b,r,t]) == 1:\n",
    "                ma_viol.append({\"id_a\": P_ids[a], \"nome_a\": names[a], \"id_b\": P_ids[b], \"nome_b\": names[b],\n",
    "                                \"rodada\": r, \"mesa\": t})\n",
    "must_avoid_violations = pd.DataFrame(ma_viol)\n",
    "\n",
    "# Checagem extra: fixos realmente permaneceram na mesma mesa (e na mesa certa)\n",
    "fixed_check = []\n",
    "for i, mf in fixed_info.items():\n",
    "    mesas_i = sorted(schedule_df.query(\"id == @P_ids[i]\")[\"mesa\"].unique().tolist())\n",
    "    fixed_check.append({\n",
    "        \"id\": P_ids[i], \"nome\": names[i], \"mesa_fixa_esperada\": mf, \"mesas_encontradas\": mesas_i,\n",
    "        \"ok\": (mesas_i == [mf])\n",
    "    })\n",
    "fixed_check_df = pd.DataFrame(fixed_check)\n",
    "\n",
    "print(\"Resumo:\")\n",
    "print(\"- must_together atendidos:\", must_together_report['atendido'].sum(), \"/\", len(must_together_report))\n",
    "print(\"- must_avoid violações   :\", len(must_avoid_violations))\n",
    "if not fixed_check_df.empty and not fixed_check_df['ok'].all():\n",
    "    print(\"[ATENÇÃO] Algum fixo não ficou 100% na mesa esperada. Veja fixed_check_df.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf909a9f",
   "metadata": {},
   "source": [
    "## Validações Gerais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b6ab2c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'schedule_wide' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Validando encontros duplicados\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mschedule_wide\u001b[49m[\n\u001b[32m      4\u001b[39m     (schedule_wide[\u001b[33m'\u001b[39m\u001b[33mp1\u001b[39m\u001b[33m'\u001b[39m] == schedule_wide[\u001b[33m'\u001b[39m\u001b[33mp2\u001b[39m\u001b[33m'\u001b[39m]) |\n\u001b[32m      5\u001b[39m     (schedule_wide[\u001b[33m'\u001b[39m\u001b[33mp1\u001b[39m\u001b[33m'\u001b[39m] == schedule_wide[\u001b[33m'\u001b[39m\u001b[33mp3\u001b[39m\u001b[33m'\u001b[39m]) |\n\u001b[32m      6\u001b[39m     (schedule_wide[\u001b[33m'\u001b[39m\u001b[33mp1\u001b[39m\u001b[33m'\u001b[39m] == schedule_wide[\u001b[33m'\u001b[39m\u001b[33mp4\u001b[39m\u001b[33m'\u001b[39m]) |\n\u001b[32m      7\u001b[39m     (schedule_wide[\u001b[33m'\u001b[39m\u001b[33mp2\u001b[39m\u001b[33m'\u001b[39m] == schedule_wide[\u001b[33m'\u001b[39m\u001b[33mp3\u001b[39m\u001b[33m'\u001b[39m]) |\n\u001b[32m      8\u001b[39m     (schedule_wide[\u001b[33m'\u001b[39m\u001b[33mp2\u001b[39m\u001b[33m'\u001b[39m] == schedule_wide[\u001b[33m'\u001b[39m\u001b[33mp4\u001b[39m\u001b[33m'\u001b[39m]) |\n\u001b[32m      9\u001b[39m     (schedule_wide[\u001b[33m'\u001b[39m\u001b[33mp3\u001b[39m\u001b[33m'\u001b[39m] == schedule_wide[\u001b[33m'\u001b[39m\u001b[33mp4\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     10\u001b[39m ]\n",
      "\u001b[31mNameError\u001b[39m: name 'schedule_wide' is not defined"
     ]
    }
   ],
   "source": [
    "# Validando encontros duplicados\n",
    "\n",
    "schedule_wide[\n",
    "    (schedule_wide['p1'] == sc hedule_wide['p2']) |\n",
    "    (schedule_wide['p1'] == schedule_wide['p3']) |\n",
    "    (schedule_wide['p1'] == schedule_wide['p4']) |\n",
    "    (schedule_wide['p2'] == schedule_wide['p3']) |\n",
    "    (schedule_wide['p2'] == schedule_wide['p4']) |\n",
    "    (schedule_wide['p3'] == schedule_wide['p4'])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206e4bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Validações avançadas / KPIs\n",
    "# Pré: schedule_df, participants, must_together, must_avoid, affinity_overrides\n",
    "# =========================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "\n",
    "# --------- helpers ----------\n",
    "def _col(df, *cands):\n",
    "    m = {c.lower(): c for c in df.columns}\n",
    "    for c in cands:\n",
    "        if c and c.lower() in m:\n",
    "            return m[c.lower()]\n",
    "    return None\n",
    "\n",
    "pid = _col(schedule_df, 'id')\n",
    "rod = _col(schedule_df, 'rodada')\n",
    "tab = _col(schedule_df, 'mesa')\n",
    "ram = _col(schedule_df, 'ramo_norm') or _col(schedule_df,'ramo')\n",
    "name = _col(schedule_df, 'nome_pessoa') or _col(schedule_df,'nome')\n",
    "emp  = _col(schedule_df, 'nome_empresa') or _col(schedule_df,'empresa')\n",
    "\n",
    "if not all([pid, rod, tab, ram]):\n",
    "    raise ValueError(\"schedule_df precisa conter: id, rodada, mesa, ramo_norm/ramo.\")\n",
    "\n",
    "# matriz de similaridade (0..1) baseada em affinity_overrides + defaults\n",
    "DEFAULT_SIM_SAME = 0.30\n",
    "DEFAULT_SIM_DIFF = 0.55\n",
    "cols = {c.lower(): c for c in affinity_overrides.columns}\n",
    "ra = cols.get('ramo_a', list(affinity_overrides.columns)[0])\n",
    "rb = cols.get('ramo_b', list(affinity_overrides.columns)[1])\n",
    "rs = cols.get('sim',    list(affinity_overrides.columns)[2])\n",
    "\n",
    "def sim_lookup(a, b):\n",
    "    a = str(a).strip().lower()\n",
    "    b = str(b).strip().lower()\n",
    "    mask = (affinity_overrides[ra].str.strip().str.lower().eq(a) &\n",
    "            affinity_overrides[rb].str.strip().str.lower().eq(b))\n",
    "    v = affinity_overrides.loc[mask, rs]\n",
    "    if not v.empty:\n",
    "        return float(v.iloc[0])\n",
    "    mask = (affinity_overrides[ra].str.strip().str.lower().eq(b) &\n",
    "            affinity_overrides[rb].str.strip().str.lower().eq(a))\n",
    "    v = affinity_overrides.loc[mask, rs]\n",
    "    if not v.empty:\n",
    "        return float(v.iloc[0])\n",
    "    return DEFAULT_SIM_SAME if a == b else DEFAULT_SIM_DIFF\n",
    "\n",
    "# ---------- 1) Diversidade e afinidade por mesa ----------\n",
    "def sim_pairwise_mean(g):\n",
    "    # g: DF de uma mesa em uma rodada\n",
    "    inds = g[ram].tolist()\n",
    "    if len(inds) < 2:\n",
    "        return np.nan\n",
    "    sims = []\n",
    "    for a,b in combinations(inds,2):\n",
    "        sims.append(sim_lookup(a,b))\n",
    "    return np.mean(sims) if sims else np.nan\n",
    "\n",
    "def simpson_diversity(g):\n",
    "    # 1 - sum(p_i^2), quanto mais perto de 1, mais diverso (com 4 pessoas, max=0.75 quando 4 ramos distintos)\n",
    "    counts = g[ram].value_counts(normalize=True)\n",
    "    return float(1 - np.sum(counts**2))\n",
    "\n",
    "by_table = (schedule_df\n",
    "            .groupby([rod, tab])\n",
    "            .apply(lambda g: pd.Series({\n",
    "                \"n_pessoas\": len(g),\n",
    "                \"ramos_unicos\": g[ram].nunique(),\n",
    "                \"simpson_div\": simpson_diversity(g),\n",
    "                \"sim_pair_mean\": sim_pairwise_mean(g)\n",
    "            }))\n",
    "            .reset_index()\n",
    "            .sort_values([rod, tab]))\n",
    "\n",
    "# ---------- 2) KPI por rodada: distribuição de diversidade ----------\n",
    "kpi_round = (by_table\n",
    "             .assign(flag4=lambda d: (d['ramos_unicos']==4).astype(int),\n",
    "                     flag3=lambda d: (d['ramos_unicos']==3).astype(int),\n",
    "                     flag2=lambda d: (d['ramos_unicos']==2).astype(int),\n",
    "                     flag1=lambda d: (d['ramos_unicos']==1).astype(int))\n",
    "             .groupby(rod)\n",
    "             .agg(\n",
    "                 mesas=('mesa','count'),\n",
    "                 pct_4_ramos=('flag4', lambda x: round(100*x.mean(),2)),\n",
    "                 pct_3_ramos=('flag3', lambda x: round(100*x.mean(),2)),\n",
    "                 pct_2_ramos=('flag2', lambda x: round(100*x.mean(),2)),\n",
    "                 pct_1_ramo =('flag1', lambda x: round(100*x.mean(),2)),\n",
    "                 afinidade_media=('sim_pair_mean','mean'),\n",
    "                 simpson_medio =('simpson_div','mean')\n",
    "             )\n",
    "             .reset_index())\n",
    "\n",
    "print(\"=== KPI por rodada (diversidade & afinidade) ===\")\n",
    "display(kpi_round)\n",
    "\n",
    "# ---------- 3) Parceiros por pessoa (únicos, repetidos, mesmo ramo) ----------\n",
    "# lista de parceiros por (rodada, mesa)\n",
    "pairs_rt = schedule_df.groupby([rod, tab]).apply(lambda g: list(combinations(sorted(g[pid]),2))).explode()\n",
    "pairs_rt = pairs_rt.dropna().reset_index(name='pair')\n",
    "pairs_rt[['id_a','id_b']] = pd.DataFrame(pairs_rt['pair'].tolist(), index=pairs_rt.index)\n",
    "pairs_rt = pairs_rt.drop(columns=['pair'])\n",
    "\n",
    "# parceiros únicos por pessoa\n",
    "partners = defaultdict(set)\n",
    "partners_same_industry = defaultdict(int)\n",
    "id_to_ind = dict(zip(schedule_df[pid], schedule_df[ram]))\n",
    "for _, row in pairs_rt.iterrows():\n",
    "    a,b = int(row['id_a']), int(row['id_b'])\n",
    "    partners[a].add(b); partners[b].add(a)\n",
    "    if id_to_ind.get(a) == id_to_ind.get(b):\n",
    "        partners_same_industry[a] += 1\n",
    "        partners_same_industry[b] += 1\n",
    "\n",
    "df_partners = pd.DataFrame({\n",
    "    \"id\": list(schedule_df[pid].unique())\n",
    "})\n",
    "df_partners['n_parceiros_unicos'] = df_partners['id'].map(lambda x: len(partners.get(x,set())))\n",
    "df_partners['reps_mesmo_ramo']   = df_partners['id'].map(lambda x: partners_same_industry.get(x,0))\n",
    "# máximo teórico de parceiros únicos em 4 rodadas com mesas de 4 = 12\n",
    "df_partners['max_teorico'] = 12\n",
    "df_partners['gap_parceiros'] = df_partners['max_teorico'] - df_partners['n_parceiros_unicos']\n",
    "\n",
    "print(\"=== Pessoas com menos parceiros únicos (top 15) ===\")\n",
    "display(df_partners.sort_values(['n_parceiros_unicos','reps_mesmo_ramo'], ascending=[True, True]).head(15))\n",
    "\n",
    "print(\"=== Pessoas que mais sentaram com mesmo ramo (top 15) ===\")\n",
    "display(df_partners.sort_values('reps_mesmo_ramo', ascending=False).head(15))\n",
    "\n",
    "# ---------- 4) Repetição de parceiro (não must_together) > 1 ----------\n",
    "# conta encontros por par\n",
    "enc_by_pair = (pairs_rt.groupby(['id_a','id_b'])\n",
    "               .size().reset_index(name='encontros'))\n",
    "# normaliza ordem (id_a < id_b)\n",
    "enc_by_pair['a'] = enc_by_pair[['id_a','id_b']].min(axis=1)\n",
    "enc_by_pair['b'] = enc_by_pair[['id_a','id_b']].max(axis=1)\n",
    "enc_by_pair = (enc_by_pair.groupby(['a','b'])['encontros'].sum()\n",
    "               .reset_index().rename(columns={'a':'id_a','b':'id_b'}))\n",
    "\n",
    "# remove must_together da checagem\n",
    "mt_cols = {c.lower(): c for c in must_together.columns}\n",
    "mta = mt_cols.get('id_a', list(must_together.columns)[0])\n",
    "mtb = mt_cols.get('id_b', list(must_together.columns)[1])\n",
    "mt_set = set(tuple(sorted((int(r[mta]), int(r[mtb])))) for _,r in must_together.iterrows())\n",
    "\n",
    "rep_nao_mt = enc_by_pair[(enc_by_pair['encontros'] > 1) &\n",
    "                         (~enc_by_pair.apply(lambda r: (r['id_a'], r['id_b']) in mt_set, axis=1))]\n",
    "print(\"=== Pares repetidos (>1) que não são must_together ===\")\n",
    "display(rep_nao_mt.sort_values('encontros', ascending=False))\n",
    "\n",
    "# ---------- 5) Repetição de MESA por pessoa (ideal: 4 mesas distintas) ----------\n",
    "mesas_por_pessoa = (schedule_df.groupby([pid])[tab].nunique()\n",
    "                    .reset_index().rename(columns={tab:'mesas_distintas'}))\n",
    "mesas_por_pessoa['ideal'] = 4\n",
    "mesas_por_pessoa['gap'] = mesas_por_pessoa['ideal'] - mesas_por_pessoa['mesas_distintas']\n",
    "rep_mesa = mesas_por_pessoa[mesas_por_pessoa['mesas_distintas'] < 4].sort_values('mesas_distintas')\n",
    "print(\"=== Pessoas que repetiram mesa entre rodadas ===\")\n",
    "display(rep_mesa.head(20))\n",
    "\n",
    "# ---------- 6) Mesas críticas (baixa diversidade / alta homogeneidade) ----------\n",
    "criticas = by_table.sort_values(['ramos_unicos','simpson_div','sim_pair_mean']).query(\"n_pessoas==4\").head(20)\n",
    "print(\"=== Mesas mais críticas (ordenadas por baixa diversidade) ===\")\n",
    "display(criticas)\n",
    "\n",
    "# ---------- 7) Afinidade média por mesa (útil p/ ver “quão diversa” ficou sob sua métrica) ----------\n",
    "print(\"=== Top 20 mesas com MAIOR afinidade média (complementaridades fortes) ===\")\n",
    "display(by_table.sort_values('sim_pair_mean', ascending=False).head(20))\n",
    "\n",
    "print(\"=== Top 20 mesas com MENOR afinidade média (potencial ajuste) ===\")\n",
    "display(by_table.sort_values('sim_pair_mean', ascending=True).head(20))\n",
    "\n",
    "# ---------- 8) Preferências: cobertura por pessoa (teve pelo menos 1 encontro compatível ao longo do evento?) ----------\n",
    "# reconstruir prefs da base participantes (caso schedule_df não tenha)\n",
    "p_id = _col(participants, 'id')\n",
    "pf1  = _col(participants, 'pref1_norm') or _col(participants, 'pref1_ramo')\n",
    "pf2  = _col(participants, 'pref2_norm') or _col(participants, 'pref2_ramo')\n",
    "pf3  = _col(participants, 'pref3_norm') or _col(participants, 'pref3_ramo')\n",
    "rP   = _col(participants, 'ramo_norm') or _col(participants, 'ramo')\n",
    "\n",
    "tmpP = participants[[p_id, rP, pf1, pf2, pf3]].copy()\n",
    "tmpP.columns = ['id','ramo_norm','pref1','pref2','pref3']\n",
    "schedP = schedule_df.merge(tmpP, on='id', how='left', suffixes=('','_p'))\n",
    "\n",
    "# checa, para cada pessoa, em cada rodada, se teve ao menos 1 parceiro do ramo em suas prefs\n",
    "def _prefs_set(row):\n",
    "    s=set()\n",
    "    for c in ['pref1','pref2','pref3']:\n",
    "        v = str(row[c]).strip().lower()\n",
    "        if v and v!='nan': s.add(v)\n",
    "    return s\n",
    "\n",
    "schedP['_prefset'] = schedP.apply(_prefs_set, axis=1)\n",
    "has_pref = schedP['_prefset'].apply(lambda s: len(s)>0)\n",
    "\n",
    "pref_hits = []\n",
    "for (r,t), g in schedP.groupby([rod, tab]):\n",
    "    ids = list(g['id'])\n",
    "    ramo_map = dict(zip(g['id'], g[ram]))\n",
    "    pref_map = dict(zip(g['id'], g['_prefset']))\n",
    "    for i in ids:\n",
    "        if len(pref_map[i])==0: \n",
    "            continue\n",
    "        others = [j for j in ids if j != i]\n",
    "        ok = any(ramo_map[j] in pref_map[i] for j in others)\n",
    "        pref_hits.append((i,r,ok))\n",
    "\n",
    "pref_df = pd.DataFrame(pref_hits, columns=['id','rodada','hit'])\n",
    "# cobertura ao longo do evento (>=1 rodada)\n",
    "cov_evento = (pref_df.groupby('id')['hit'].max().reset_index()\n",
    "              .merge(tmpP[['id']], on='id', how='right'))\n",
    "cov_evento['has_pref'] = participants[p_id].map(lambda x: len(_prefs_set(tmpP[tmpP['id']==x].iloc[0]))>0)\n",
    "cov_evento = cov_evento[cov_evento['has_pref']==True]\n",
    "cov_evento['hit'] = cov_evento['hit'].fillna(False)\n",
    "\n",
    "print(\"=== Cobertura de preferências ao longo do evento ===\")\n",
    "total_com_pref = cov_evento.shape[0]\n",
    "atendidos = int(cov_evento['hit'].sum())\n",
    "print(f\"- Pessoas com preferência: {total_com_pref}\")\n",
    "print(f\"- Atendidas >=1x:         {atendidos}  ({round(100*atendidos/max(1,total_com_pref),2)}%)\")\n",
    "\n",
    "nao_atendidos = cov_evento[cov_evento['hit']==False]['id'].tolist()\n",
    "df_nao_atendidos = schedule_df[schedule_df['id'].isin(nao_atendidos)][['id', name, emp]].drop_duplicates()\n",
    "print(\"=== Pessoas com pref. que NÃO tiveram encontro compatível (listar p/ ajustes finos) ===\")\n",
    "display(df_nao_atendidos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099f3335",
   "metadata": {},
   "outputs": [],
   "source": [
    "backtesting_path = fr'C:\\Users\\felip\\Documents\\FELIPE\\Netweaving_Conecta\\backtesting'\n",
    "os.chdir(backtesting_path)\n",
    "\n",
    "# pasta de saída (mude se quiser)\n",
    "stamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "out_dir = f\"exports_{stamp}\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "def _exists(name):\n",
    "    return name in globals() and isinstance(globals()[name], pd.DataFrame)\n",
    "\n",
    "def _save(name, filename=None):\n",
    "    if not _exists(name):\n",
    "        return None\n",
    "    df = globals()[name]\n",
    "    fn = filename or f\"{name}.csv\"\n",
    "    path = os.path.join(out_dir, fn)\n",
    "    try:\n",
    "        df.to_csv(path, index=False, encoding=\"utf-8-sig\")\n",
    "        return {\"name\": name, \"file\": fn, \"rows\": len(df), \"cols\": list(df.columns)}\n",
    "    except Exception as e:\n",
    "        return {\"name\": name, \"file\": fn, \"error\": str(e)}\n",
    "\n",
    "# lista de possíveis DFs a exportar (adicione/remova se quiser)\n",
    "candidates = [\n",
    "    # principais\n",
    "    \"schedule_df\", \"schedule_wide\",\n",
    "    # validações básicas\n",
    "    \"viol_once_per_round\", \"viol_four_total\", \"viol_capacity\", \"missing_tables_df\",\n",
    "    \"fixed_mismatch\", \"must_avoid_violations\", \"must_together_unmet\",\n",
    "    \"repeat_pairs_df\", \"diversity_viol\",\n",
    "    # preferências (do primeiro pacote)\n",
    "    \"pref_global\", \"pref_by_round\", \"pref_unserved\", \"top_pairs\",\n",
    "    # KPIs/validações avançadas\n",
    "    \"by_table\", \"kpi_round\", \"df_partners\", \"rep_nao_mt\", \"rep_mesa\", \"criticas\"\n",
    "]\n",
    "\n",
    "manifest = []\n",
    "for name in candidates:\n",
    "    rec = _save(name)\n",
    "    if rec: manifest.append(rec)\n",
    "\n",
    "# também salva um manifesto .csv e imprime um resumo\n",
    "manifest_df = pd.DataFrame(manifest)\n",
    "manifest_path = os.path.join(out_dir, \"_manifest.csv\")\n",
    "manifest_df.to_csv(manifest_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"Arquivos salvos em: {out_dir}\")\n",
    "if not manifest_df.empty:\n",
    "    display(manifest_df[[\"name\",\"file\",\"rows\"]])\n",
    "else:\n",
    "    print(\"Nenhum DataFrame esperado foi encontrado no ambiente.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ab0467",
   "metadata": {},
   "source": [
    "## Validações Individuais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a46de16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando se os que deveriam ser fixos realmente ficaram nas mesmas mesas\n",
    "nomes = [\n",
    "    \"Caroline Scorvo\",\n",
    "    \"Cleiton Vicente\",\n",
    "    \"Fabiano Souza Ramos\",\n",
    "    \"Márcia Fonseca Borges\",\n",
    "    \"Nanci Toledo\",\n",
    "    \"Tiago Oliveira\"\n",
    "]\n",
    "\n",
    "for nome in nomes:\n",
    "    temp = schedule_wide[\n",
    "        (schedule_wide['p1'] == nome) | (schedule_wide['p2'] == nome) | (schedule_wide['p3'] == nome) | (schedule_wide['p4'] == nome)\n",
    "    ]\n",
    "    unicos = temp['mesa'].unique()\n",
    "    n_unicos = temp['mesa'].nunique()\n",
    "    print(f\"{nome} - Mesas únicas: {n_unicos} - Mesas: {list(unicos)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1c1825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste Individual\n",
    "nome = \"Deise Gressens\"\n",
    "\n",
    "schedule_wide[\n",
    "        (schedule_wide['p1'] == nome) | (schedule_wide['p2'] == nome) | (schedule_wide['p3'] == nome) | (schedule_wide['p4'] == nome)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7ebbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primeira rodada Cidinha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed441d83",
   "metadata": {},
   "source": [
    "**Potenciais Melhorias**\n",
    "- Primeira Rodada Cidinha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f996e67",
   "metadata": {},
   "source": [
    "## Formatação Desejada Tabela Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9cc36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(fr\"C:\\Users\\felip\\Documents\\FELIPE\\Netweaving_Conecta\")\n",
    "schedule_wide.to_csv('schedule_wide.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fea382",
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524aba1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1a196f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gera df_final_premium (fixos) e df_final_standard (móveis)\n",
    "# Fonte da verdade para FIXO = schedule_wide (mesma mesa nas 4 rodadas)\n",
    "# Usa participants só para preencher EMPRESA. Não depende de Fixo/Mesa_Fixa do participants.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "\n",
    "# aceita tanto schedule_wide quanto schedue_wide (typo)\n",
    "if 'schedule_wide' not in globals() and 'schedue_wide' in globals():\n",
    "    schedule_wide = schedue_wide\n",
    "\n",
    "def _strip(s):\n",
    "    if pd.isna(s): return \"\"\n",
    "    s = unicodedata.normalize(\"NFKD\", str(s).strip())\n",
    "    return \"\".join(c for c in s if not unicodedata.combining(c))\n",
    "\n",
    "def _det(df, *names):\n",
    "    m = {c.lower(): c for c in df.columns}\n",
    "    for n in names:\n",
    "        if n and n.lower() in m:\n",
    "            return m[n.lower()]\n",
    "    return None\n",
    "\n",
    "# 1) schedule_wide -> long\n",
    "id_cols   = [c for c in schedule_wide.columns if c.lower() in {\"rodada\",\"mesa\"}]\n",
    "seat_cols = [c for c in schedule_wide.columns if c.lower().startswith(\"p\")]\n",
    "sw_long = (\n",
    "    schedule_wide.melt(id_vars=id_cols, value_vars=seat_cols,\n",
    "                       var_name=\"seat\", value_name=\"nome_pessoa\")\n",
    "    .dropna(subset=[\"nome_pessoa\"])\n",
    "    .copy()\n",
    ")\n",
    "sw_long[\"mesa_label\"]   = (sw_long[\"mesa\"].astype(int) + 1).map(lambda x: f\"MESA {x}\")\n",
    "sw_long[\"rodada_label\"] = (sw_long[\"rodada\"].astype(int) + 1).map(lambda x: f\"{x}ª RODADA\")\n",
    "\n",
    "# 2) FIXO pelo schedule: quem ficou na MESMA mesa em todas as rodadas\n",
    "mesas_dist = sw_long.groupby(\"nome_pessoa\")[\"mesa\"].nunique()\n",
    "fixed_by_schedule = mesas_dist.eq(1).astype(int).rename(\"FIXO\").reset_index()\n",
    "\n",
    "# mesa fixa (rótulo) derivada do schedule\n",
    "mesa_fixa_num = (\n",
    "    sw_long.groupby(\"nome_pessoa\")[\"mesa\"]\n",
    "           .agg(lambda s: s.iloc[0] if s.nunique()==1 else np.nan)\n",
    "           .rename(\"MESA_FIXA_NUM\")\n",
    "           .reset_index()\n",
    ")\n",
    "mesa_fixa_num[\"MESA_FIXA\"] = mesa_fixa_num[\"MESA_FIXA_NUM\"].apply(\n",
    "    lambda v: f\"MESA {int(v)+1}\" if pd.notna(v) else np.nan\n",
    ")\n",
    "\n",
    "# 3) EMPRESA via participants (sem afetar FIXO)\n",
    "c_nome    = _det(participants, \"Nome_Pessoa\",\"nome_pessoa\",\"Nome\",\"Pessoa\",\"nome\")\n",
    "c_empresa = _det(participants, \"Nome_Empresa\",\"nome_empresa\",\"Empresa\",\"empresa\")\n",
    "\n",
    "parts = participants.copy()\n",
    "parts[\"_nome_key\"] = parts[c_nome].map(lambda s: _strip(s).lower())\n",
    "emp_por_nome = (\n",
    "    parts.groupby(\"_nome_key\")[c_empresa]\n",
    "         .apply(lambda s: next((x for x in s if pd.notna(x) and str(x).strip()!=''), \"\"))\n",
    "         .rename(\"EMPRESA\")\n",
    "         .reset_index()\n",
    ")\n",
    "\n",
    "sw_long[\"_nome_key\"] = sw_long[\"nome_pessoa\"].map(lambda s: _strip(s).lower())\n",
    "\n",
    "# 4) base por pessoa (merge correto pela _nome_key)\n",
    "pessoas = (sw_long[[\"nome_pessoa\",\"_nome_key\"]].drop_duplicates()\n",
    "           .merge(fixed_by_schedule, on=\"nome_pessoa\", how=\"left\")\n",
    "           .merge(mesa_fixa_num, on=\"nome_pessoa\", how=\"left\")\n",
    "           .merge(emp_por_nome, on=\"_nome_key\", how=\"left\")\n",
    "           .drop(columns=[\"_nome_key\"])\n",
    "           .rename(columns={\"nome_pessoa\":\"NOME\"}))\n",
    "pessoas[\"EMPRESA\"] = pessoas[\"EMPRESA\"].fillna(\"\").astype(str)\n",
    "\n",
    "# 5) rodada × mesa por pessoa\n",
    "rodada_mesa = (sw_long\n",
    "    .pivot_table(index=\"nome_pessoa\", columns=\"rodada_label\",\n",
    "                 values=\"mesa_label\", aggfunc=\"first\")\n",
    "    .reset_index()\n",
    "    .rename(columns={\"nome_pessoa\":\"NOME\"})\n",
    ")\n",
    "\n",
    "# 6) consolidação e split\n",
    "pivot = pessoas.merge(rodada_mesa, on=\"NOME\", how=\"left\")\n",
    "rod_cols = [c for c in [\"1ª RODADA\",\"2ª RODADA\",\"3ª RODADA\",\"4ª RODADA\"] if c in pivot.columns]\n",
    "pivot = pivot[[\"NOME\",\"EMPRESA\",\"FIXO\",\"MESA_FIXA\"] + rod_cols]\n",
    "\n",
    "df_final_premium  = pivot[pivot[\"FIXO\"]==1].copy()\n",
    "df_final_standard = pivot[pivot[\"FIXO\"]==0].copy()\n",
    "\n",
    "# ordenação\n",
    "if not df_final_premium.empty:\n",
    "    ord_ = df_final_premium[\"MESA_FIXA\"].str.extract(r\"(\\d+)\")[0].astype(float)\n",
    "    df_final_premium = (df_final_premium\n",
    "                        .assign(_ord=ord_).sort_values([\"_ord\",\"NOME\"])\n",
    "                        .drop(columns=[\"_ord\"]))\n",
    "df_final_standard = df_final_standard.sort_values(\"NOME\")\n",
    "df_final_standard = df_final_standard.drop(columns=[\"FIXO\",\"MESA_FIXA\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0905b8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_path = fr'C:\\Users\\felip\\Documents\\FELIPE\\Netweaving_Conecta\\saida_final'\n",
    "os.chdir(final_path)\n",
    "\n",
    "df_final_standard.to_excel('df_final_standard.xlsx', index=False)\n",
    "df_final_premium.to_excel('df_final_premium.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
